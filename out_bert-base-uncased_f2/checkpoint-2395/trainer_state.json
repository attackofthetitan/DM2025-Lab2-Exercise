{
  "best_global_step": 2395,
  "best_metric": 0.49849415482770504,
  "best_model_checkpoint": "./out_bert-base-uncased_f2/checkpoint-2395",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 2395,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.020876826722338204,
      "grad_norm": 5.052124500274658,
      "learning_rate": 1.4897703549060544e-05,
      "loss": 1.5178,
      "step": 50
    },
    {
      "epoch": 0.04175365344467641,
      "grad_norm": 6.709364414215088,
      "learning_rate": 1.4793319415448852e-05,
      "loss": 1.3483,
      "step": 100
    },
    {
      "epoch": 0.06263048016701461,
      "grad_norm": 5.457127094268799,
      "learning_rate": 1.468893528183716e-05,
      "loss": 1.2926,
      "step": 150
    },
    {
      "epoch": 0.08350730688935282,
      "grad_norm": 9.219525337219238,
      "learning_rate": 1.458455114822547e-05,
      "loss": 1.1586,
      "step": 200
    },
    {
      "epoch": 0.10438413361169102,
      "grad_norm": 12.599611282348633,
      "learning_rate": 1.448016701461378e-05,
      "loss": 1.1673,
      "step": 250
    },
    {
      "epoch": 0.12526096033402923,
      "grad_norm": 13.869726181030273,
      "learning_rate": 1.4375782881002088e-05,
      "loss": 1.1219,
      "step": 300
    },
    {
      "epoch": 0.14613778705636743,
      "grad_norm": 9.73603343963623,
      "learning_rate": 1.4271398747390397e-05,
      "loss": 1.0238,
      "step": 350
    },
    {
      "epoch": 0.16701461377870563,
      "grad_norm": 8.016270637512207,
      "learning_rate": 1.4167014613778707e-05,
      "loss": 1.0425,
      "step": 400
    },
    {
      "epoch": 0.18789144050104384,
      "grad_norm": 5.670461177825928,
      "learning_rate": 1.4062630480167015e-05,
      "loss": 1.0758,
      "step": 450
    },
    {
      "epoch": 0.20876826722338204,
      "grad_norm": 8.648615837097168,
      "learning_rate": 1.3958246346555323e-05,
      "loss": 1.0431,
      "step": 500
    },
    {
      "epoch": 0.22964509394572025,
      "grad_norm": 7.0128326416015625,
      "learning_rate": 1.3853862212943631e-05,
      "loss": 1.0592,
      "step": 550
    },
    {
      "epoch": 0.25052192066805845,
      "grad_norm": 7.115601539611816,
      "learning_rate": 1.3749478079331943e-05,
      "loss": 0.9929,
      "step": 600
    },
    {
      "epoch": 0.27139874739039666,
      "grad_norm": 7.521945476531982,
      "learning_rate": 1.3645093945720251e-05,
      "loss": 1.0303,
      "step": 650
    },
    {
      "epoch": 0.29227557411273486,
      "grad_norm": 7.13806676864624,
      "learning_rate": 1.354070981210856e-05,
      "loss": 1.0513,
      "step": 700
    },
    {
      "epoch": 0.31315240083507306,
      "grad_norm": 7.0486931800842285,
      "learning_rate": 1.343632567849687e-05,
      "loss": 0.9964,
      "step": 750
    },
    {
      "epoch": 0.33402922755741127,
      "grad_norm": 8.664778709411621,
      "learning_rate": 1.3331941544885178e-05,
      "loss": 0.9852,
      "step": 800
    },
    {
      "epoch": 0.35490605427974947,
      "grad_norm": 14.156485557556152,
      "learning_rate": 1.3227557411273486e-05,
      "loss": 0.9695,
      "step": 850
    },
    {
      "epoch": 0.3757828810020877,
      "grad_norm": 6.441669464111328,
      "learning_rate": 1.3123173277661796e-05,
      "loss": 0.9948,
      "step": 900
    },
    {
      "epoch": 0.3966597077244259,
      "grad_norm": 8.572488784790039,
      "learning_rate": 1.3018789144050106e-05,
      "loss": 0.9484,
      "step": 950
    },
    {
      "epoch": 0.4175365344467641,
      "grad_norm": 8.742874145507812,
      "learning_rate": 1.2914405010438414e-05,
      "loss": 0.9236,
      "step": 1000
    },
    {
      "epoch": 0.4384133611691023,
      "grad_norm": 7.310985565185547,
      "learning_rate": 1.2810020876826722e-05,
      "loss": 0.987,
      "step": 1050
    },
    {
      "epoch": 0.4592901878914405,
      "grad_norm": 7.482316493988037,
      "learning_rate": 1.270563674321503e-05,
      "loss": 0.9993,
      "step": 1100
    },
    {
      "epoch": 0.4801670146137787,
      "grad_norm": 6.687304496765137,
      "learning_rate": 1.260125260960334e-05,
      "loss": 0.9308,
      "step": 1150
    },
    {
      "epoch": 0.5010438413361169,
      "grad_norm": 8.115198135375977,
      "learning_rate": 1.249686847599165e-05,
      "loss": 0.9242,
      "step": 1200
    },
    {
      "epoch": 0.5219206680584552,
      "grad_norm": 12.110508918762207,
      "learning_rate": 1.2392484342379958e-05,
      "loss": 0.9428,
      "step": 1250
    },
    {
      "epoch": 0.5427974947807933,
      "grad_norm": 7.447290420532227,
      "learning_rate": 1.2288100208768268e-05,
      "loss": 0.9255,
      "step": 1300
    },
    {
      "epoch": 0.5636743215031316,
      "grad_norm": 9.585230827331543,
      "learning_rate": 1.2183716075156576e-05,
      "loss": 1.0042,
      "step": 1350
    },
    {
      "epoch": 0.5845511482254697,
      "grad_norm": 8.079805374145508,
      "learning_rate": 1.2079331941544885e-05,
      "loss": 0.9444,
      "step": 1400
    },
    {
      "epoch": 0.605427974947808,
      "grad_norm": 8.561686515808105,
      "learning_rate": 1.1974947807933193e-05,
      "loss": 0.9752,
      "step": 1450
    },
    {
      "epoch": 0.6263048016701461,
      "grad_norm": 3.58896541595459,
      "learning_rate": 1.1870563674321505e-05,
      "loss": 0.923,
      "step": 1500
    },
    {
      "epoch": 0.6471816283924844,
      "grad_norm": 8.24744701385498,
      "learning_rate": 1.1766179540709813e-05,
      "loss": 0.9841,
      "step": 1550
    },
    {
      "epoch": 0.6680584551148225,
      "grad_norm": 9.964653015136719,
      "learning_rate": 1.1661795407098121e-05,
      "loss": 0.9675,
      "step": 1600
    },
    {
      "epoch": 0.6889352818371608,
      "grad_norm": 7.752355575561523,
      "learning_rate": 1.1557411273486431e-05,
      "loss": 0.9147,
      "step": 1650
    },
    {
      "epoch": 0.7098121085594989,
      "grad_norm": 6.3510026931762695,
      "learning_rate": 1.1453027139874739e-05,
      "loss": 0.9919,
      "step": 1700
    },
    {
      "epoch": 0.7306889352818372,
      "grad_norm": 4.213176250457764,
      "learning_rate": 1.1348643006263047e-05,
      "loss": 0.9281,
      "step": 1750
    },
    {
      "epoch": 0.7515657620041754,
      "grad_norm": 9.171894073486328,
      "learning_rate": 1.1244258872651357e-05,
      "loss": 0.9263,
      "step": 1800
    },
    {
      "epoch": 0.7724425887265136,
      "grad_norm": 6.641151428222656,
      "learning_rate": 1.1139874739039667e-05,
      "loss": 0.938,
      "step": 1850
    },
    {
      "epoch": 0.7933194154488518,
      "grad_norm": 7.1037445068359375,
      "learning_rate": 1.1035490605427975e-05,
      "loss": 0.959,
      "step": 1900
    },
    {
      "epoch": 0.81419624217119,
      "grad_norm": 6.312374114990234,
      "learning_rate": 1.0931106471816284e-05,
      "loss": 0.9579,
      "step": 1950
    },
    {
      "epoch": 0.8350730688935282,
      "grad_norm": 6.553689956665039,
      "learning_rate": 1.0826722338204592e-05,
      "loss": 0.9569,
      "step": 2000
    },
    {
      "epoch": 0.8559498956158664,
      "grad_norm": 7.3081464767456055,
      "learning_rate": 1.0722338204592902e-05,
      "loss": 0.9462,
      "step": 2050
    },
    {
      "epoch": 0.8768267223382046,
      "grad_norm": 5.5574164390563965,
      "learning_rate": 1.0617954070981212e-05,
      "loss": 0.9166,
      "step": 2100
    },
    {
      "epoch": 0.8977035490605428,
      "grad_norm": 6.350376605987549,
      "learning_rate": 1.051356993736952e-05,
      "loss": 0.9268,
      "step": 2150
    },
    {
      "epoch": 0.918580375782881,
      "grad_norm": 9.954618453979492,
      "learning_rate": 1.040918580375783e-05,
      "loss": 0.9367,
      "step": 2200
    },
    {
      "epoch": 0.9394572025052192,
      "grad_norm": 5.296285629272461,
      "learning_rate": 1.0304801670146138e-05,
      "loss": 0.8981,
      "step": 2250
    },
    {
      "epoch": 0.9603340292275574,
      "grad_norm": 5.82058572769165,
      "learning_rate": 1.0200417536534446e-05,
      "loss": 0.9874,
      "step": 2300
    },
    {
      "epoch": 0.9812108559498957,
      "grad_norm": 6.085331439971924,
      "learning_rate": 1.0096033402922755e-05,
      "loss": 0.9529,
      "step": 2350
    },
    {
      "epoch": 1.0,
      "eval_f1_macro": 0.49849415482770504,
      "eval_loss": 0.9023129343986511,
      "eval_runtime": 18.4598,
      "eval_samples_per_second": 518.856,
      "eval_steps_per_second": 16.251,
      "step": 2395
    }
  ],
  "logging_steps": 50,
  "max_steps": 7185,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 660161124107712.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
